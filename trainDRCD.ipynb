{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eric88525/DRCD/blob/master/trainDRCD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Cn-gQTGhC7z"
   },
   "source": [
    "# DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "avAR5VmvfDDg",
    "outputId": "7e106c28-ff76-46de-c53c-53cee945423e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  7 15:49:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Rru4MXtiSQ0"
   },
   "source": [
    "# 該來用TPU了吧\n",
    "+ [REF](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=H9KYz-Vk4fMa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KC0vjMNQiXNu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "OxeJekGjicKH",
    "outputId": "9c2de2f9-1086-42de-bdd4-40999e825b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  5115  100  5115    0     0  57471      0 --:--:-- --:--:-- --:--:-- 57471\n",
      "Updating... This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-dev20200325 ...\n",
      "Collecting cloud-tpu-client\n",
      "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
      "Collecting google-api-python-client==1.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.15.0)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (49.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
      "Uninstalling torch-1.6.0+cu101:\n",
      "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
      "  Found existing installation: google-api-python-client 1.7.12\n",
      "    Uninstalling google-api-python-client-1.7.12:\n",
      "      Successfully uninstalled google-api-python-client-1.7.12\n",
      "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
      "Done updating TPU runtime\n",
      "  Successfully uninstalled torch-1.6.0+cu101\n",
      "Uninstalling torchvision-0.7.0+cu101:\n",
      "  Successfully uninstalled torchvision-0.7.0+cu101\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "- [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
      "Operation completed over 1 objects/83.4 MiB.                                     \n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
      "Operation completed over 1 objects/114.5 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
      "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
      "Operation completed over 1 objects/2.5 MiB.                                      \n",
      "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.5)\n",
      "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.5.0a0+d6149a7\n",
      "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: torch-xla\n",
      "Successfully installed torch-xla-1.6+e788e5b\n",
      "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.15.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.6.0a0+3c254fb\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  libomp5\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 234 kB of archives.\n",
      "After this operation, 774 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
      "Fetched 234 kB in 1s (381 kB/s)\n",
      "Selecting previously unselected package libomp5:amd64.\n",
      "(Reading database ... 144487 files and directories currently installed.)\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtoIU1Dhift5"
   },
   "outputs": [],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "v94_bCAbijGb",
    "outputId": "74eee875-db0d-4342-985d-2ccd23c442bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='xla:1')\n"
     ]
    }
   ],
   "source": [
    "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
    "device = xm.xla_device()\n",
    "t1 = torch.ones(3, 3, device = device)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gdLbhwM65G3"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "E6uc8HZegupi",
    "outputId": "5e14a96f-bf7f-475a-f05a-e3e72ee47980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/bin/bash: google-drive-ocamlfuse: command not found\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "colab_type": "code",
    "id": "r7N2Uzjegwxd",
    "outputId": "084814f9-0b90-41bb-caff-af98ee218273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e8c654093d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install opencc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pyprind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install zhon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install opencc\n",
    "!pip install pyprind\n",
    "!pip install zhon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uubPXZfugyLD",
    "outputId": "a13176bc-25cd-4e8b-c079-ee9e7b8ad9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "from time import strftime,gmtime\n",
    "from opencc import OpenCC\n",
    "import pyprind\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "from zhon.hanzi import non_stops,stops\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5RnZleZyg1jg",
    "outputId": "d0853975-f053-44b6-9001-b6b49eaa8718"
   },
   "outputs": [],
   "source": [
    "#cd ./drive/My Drive/Colab Notebooks/DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLaU5RUIqXsl"
   },
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdxaIBxO7uxY"
   },
   "source": [
    "# Get Train Dev Test\n",
    "\n",
    "+ train 8014 26936\n",
    "+ test 1000 3493\n",
    "+ dev 1000 3524\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yry9u4sI-3zb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class DRCDdataset():\n",
    "  def __init__(self,train_path=None , test_path = None ,dev_path = None):\n",
    "    \n",
    "    if train_path != None:\n",
    "      self.train = self.get_data(train_path)\n",
    "    if test_path != None:\n",
    "      self.test = self.get_data(test_path)\n",
    "    if dev_path != None:\n",
    "      self.dev = self.get_data(dev_path)\n",
    "\n",
    "  def get_data(self,path):\n",
    "    input_file = open(path)\n",
    "    ds = json.load(input_file)\n",
    "    datas = []\n",
    "    for i in range(len(ds['data'])):\n",
    "      for j in ds['data'][i]['paragraphs']:\n",
    "        context = j['context']\n",
    "        question = [q['question'] for q in j['qas']]\n",
    "        ans = [ a['answers'][0]['text'] for a in j['qas'] ]\n",
    "        #ans = [a['answers'][0]['answer_start'] for a in j['qas']]\n",
    "        #anse = [a['answers'][0]['answer_start']+len(a['answers'][0]['text'])-1 for a in j['qas']]\n",
    "        for k in range(len(question)):\n",
    "          datas.append([context,question[k],ans[k]])\n",
    "          #datas.append([context,question[k],ans[k],anse[k]])\n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7P7DpSVMcy7Y"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFAFURdNcP77"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GetDataset(Dataset):\n",
    "    def __init__(self,data,model_type,device,language):\n",
    "      self.data = data\n",
    "      self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "      self.device = device\n",
    "      self.cc = OpenCC('t2s') # tw->china\n",
    "      self.language = language\n",
    "    def __getitem__(self,idx):\n",
    "      paragraph,question,ans = self.data[idx][0] , self.data[idx][1], self.data[idx][2] \n",
    "      if self.language == 'china':\n",
    "        paragraph,question,ans = self.cc.convert(paragraph),self.cc.convert(question),self.cc.convert(ans)\n",
    "        \n",
    "      token_tensor = self.tokenizer.encode_plus(question,paragraph,max_length=512,truncation=True,pad_to_max_length=True)\n",
    "      #print(paragraph[:20],question,ans)\n",
    "      s_idx = [0]*512\n",
    "      e_idx = [0]*512\n",
    "      # 答案tok\n",
    "      s_tok = self.tokenizer.encode(ans)[1:-1]\n",
    "      # 找到開頭跟他一樣的\n",
    "      s_lsit = [i for i, x in enumerate(token_tensor['input_ids']) if x == s_tok[0]]\n",
    "      \n",
    "      for s_pos in s_lsit:\n",
    "        e_pos = s_pos+len(s_tok)\n",
    "        if e_pos > 511:\n",
    "          continue\n",
    "          \n",
    "        if token_tensor['input_ids'][s_pos:e_pos] == s_tok:\n",
    "          s_idx[s_pos] = 1\n",
    "          e_idx[e_pos-1] = 1\n",
    "          break\n",
    "      s_tensor = torch.Tensor(s_idx)\n",
    "      e_tensor = torch.Tensor(e_idx)\n",
    "      # input_ids / token_type_ids / attention_mask / s_tensor / e_tensor\n",
    "      return {'input_ids': torch.tensor(token_tensor['input_ids']).to(self.device)\n",
    "          ,'token_type_ids': torch.tensor( token_tensor['token_type_ids']).to(self.device) \n",
    "          ,'attention_mask': torch.tensor( token_tensor['attention_mask']).to(self.device)\n",
    "          ,'s_tensor': s_tensor.to(self.device)\n",
    "          ,'e_tensor': e_tensor.to(self.device)}\n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "84vSbr-Ynxkp",
    "outputId": "46e83f97-bc8b-402a-d080-cec0da695ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx = DRCDdataset(train_path='./dataset/DRCD_train.json',test_path='./dataset/DRCD_test.json',dev_path='./dataset/DRCD_dev.json')\\nprint(len(x.train),len(x.test),len(x.dev))\\ndevice = torch.device('cuda:0')\\nmodel_type = 'hfl/chinese-roberta-wwm-ext'\\nlanguage = 'china'\\nz = GetDataset(x.dev,model_type,device,language)\\ntokenizer = BertTokenizer.from_pretrained(model_type)\\ni = 10\\n\\ntok = tokenizer.convert_ids_to_tokens(z[i]['input_ids'])\\ns = z[i]['s_tensor'].tolist()\\ne = z[i]['e_tensor'].tolist()\\ntp = z[i]['token_type_ids'].tolist()\\nat = z[i]['attention_mask'].tolist()\\nfor i in range(len(tok)):\\n  print(tok[i],s[i],e[i],tp[i],at[i])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = DRCDdataset(train_path='./dataset/DRCD_train.json',test_path='./dataset/DRCD_test.json',dev_path='./dataset/DRCD_dev.json')\n",
    "print(len(x.train),len(x.test),len(x.dev))\n",
    "device = torch.device('cuda:0')\n",
    "model_type = 'hfl/chinese-roberta-wwm-ext'\n",
    "language = 'china'\n",
    "z = GetDataset(x.dev,model_type,device,language)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "i = 10\n",
    "\n",
    "tok = tokenizer.convert_ids_to_tokens(z[i]['input_ids'])\n",
    "s = z[i]['s_tensor'].tolist()\n",
    "e = z[i]['e_tensor'].tolist()\n",
    "tp = z[i]['token_type_ids'].tolist()\n",
    "at = z[i]['attention_mask'].tolist()\n",
    "for i in range(len(tok)):\n",
    "  print(tok[i],s[i],e[i],tp[i],at[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Z-zDS64xoOO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertDRCD(nn.Module):\n",
    "    def __init__(self,model_type):\n",
    "        super(bertDRCD,self).__init__()\n",
    "\n",
    "        config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
    "        self.bert_model = BertModel.from_pretrained(model_type,config = config)\n",
    "  \n",
    "        #self.s_vector = nn.Parameter(torch.randn(config.hidden_size),requires_grad=True) \n",
    "        #self.e_vector = nn.Parameter(torch.randn(config.hidden_size),requires_grad=True) \n",
    "\n",
    "        self.s_decoder = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size,config.hidden_size)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.ReLU()\n",
    "            ,nn.Linear(config.hidden_size,1)\n",
    "        ) \n",
    "        self.e_decoder = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size,config.hidden_size)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.ReLU()\n",
    "            ,nn.Linear(config.hidden_size,1)\n",
    "        )\n",
    "        #self.start()\n",
    "\n",
    "    def start(self):\n",
    "           \n",
    "      nn.init.xavier_uniform_(self.s_decoder[0].weight)\n",
    "      nn.init.constant_(self.s_decoder[0].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.s_decoder[3].weight)\n",
    "      nn.init.constant_(self.s_decoder[3].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.e_decoder[0].weight)\n",
    "      nn.init.constant_(self.e_decoder[0].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.e_decoder[3].weight)\n",
    "      nn.init.constant_(self.e_decoder[3].bias, 0)\n",
    "\n",
    "    def forward(self,input_ids=None,attention_mask=None,token_type_ids=None): \n",
    "      # hidden (batch,seq_len,hidden)\n",
    "      hidden = self.bert_model(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)[0]\n",
    "      s = self.s_decoder(hidden).squeeze()\n",
    "      M = token_type_ids.clone().float().to(hidden.device).detach()\n",
    "      M[M != 1] = float('-inf')\n",
    "      s = s+M \n",
    "      #s = torch.softmax(s,dim=-1)\n",
    "      e = self.e_decoder(hidden).squeeze()\n",
    "      e = e + M\n",
    "      #e = torch.softmax(e,dim=-1)\n",
    "      return s,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AHDfYFexq-Q"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class bertDRCD(nn.Module):\n",
    "    def __init__(self,model_type):\n",
    "        super(bertDRCD,self).__init__()\n",
    "\n",
    "        config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
    "        self.bert_model = BertModel.from_pretrained(model_type,config = config)\n",
    "  \n",
    "        self.s_vector = nn.Parameter(torch.randn(config.hidden_size),requires_grad=True) \n",
    "        self.e_vector = nn.Parameter(torch.randn(config.hidden_size),requires_grad=True) \n",
    "\n",
    "        #self.start()\n",
    "\n",
    "    def start(self):\n",
    "      self.decoder = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size,config.hidden_size)\n",
    "            ,nn.Dropout(0.1)\n",
    "            ,nn.ReLU()\n",
    "            ,nn.Linear(config.hidden_size,1)\n",
    "      )     \n",
    "      nn.init.xavier_uniform_(self.s_decoder[0].weight)\n",
    "      nn.init.constant_(self.s_decoder[0].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.s_decoder[3].weight)\n",
    "      nn.init.constant_(self.s_decoder[3].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.e_decoder[0].weight)\n",
    "      nn.init.constant_(self.e_decoder[0].bias, 0)\n",
    "      nn.init.xavier_uniform_(self.e_decoder[3].weight)\n",
    "      nn.init.constant_(self.e_decoder[3].bias, 0)\n",
    "\n",
    "    def forward(self,input_ids=None,attention_mask=None,token_type_ids=None): \n",
    "      # hidden (batch,seq_len,hidden)\n",
    "      hidden = self.bert_model(input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)[0]\n",
    "      s = torch.sum(hidden*self.s_vector,-1) # s now is (batch,seq_len)\n",
    "      M = token_type_ids.clone().float().to(hidden.device).detach()\n",
    "      M[M != 1] = float('-inf')\n",
    "      s = s+M \n",
    "      #s = torch.softmax(s,dim=-1)\n",
    "      e = torch.sum(hidden*self.e_vector,-1)\n",
    "      e = e + M\n",
    "      #e = torch.softmax(e,dim=-1)\n",
    "      return s,e\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGgoN41Cwtue"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice = torch.device('cpu')\\ndevice = torch.device('cuda:0')\\n\\nmodel_type = 'bert-base-chinese'\\nmodel = bertDRCD(model_type).to(device)\\nds = DRCDdataset(train_path='./dataset/DRCD_train.json',test_path='./dataset/DRCD_test.json',dev_path='./dataset/DRCD_dev.json')\\ndataset = GetDataset(ds.dev,model_type,device)\\ntrainLoader = DataLoader(dataset, batch_size=8  ,shuffle=True)\\ncriterion = nn.BCELoss()\\n\\nfor i , batch in enumerate(trainLoader):\\n  #print(batch)\\n  inp_ids,tok_id,att_m ,slabel,elabel = batch['input_ids'],batch['token_type_ids'],batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\\n  s,e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\\n  print(s)\\n  print(e)\\n  loss = (criterion(s,slabel) + criterion(e,elabel)) / 2\\n  print(loss)\\n  \\n  break\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device = torch.device('cpu')\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model_type = 'bert-base-chinese'\n",
    "model = bertDRCD(model_type).to(device)\n",
    "ds = DRCDdataset(train_path='./dataset/DRCD_train.json',test_path='./dataset/DRCD_test.json',dev_path='./dataset/DRCD_dev.json')\n",
    "dataset = GetDataset(ds.dev,model_type,device)\n",
    "trainLoader = DataLoader(dataset, batch_size=8  ,shuffle=True)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for i , batch in enumerate(trainLoader):\n",
    "  #print(batch)\n",
    "  inp_ids,tok_id,att_m ,slabel,elabel = batch['input_ids'],batch['token_type_ids'],batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\n",
    "  s,e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "  print(s)\n",
    "  print(e)\n",
    "  loss = (criterion(s,slabel) + criterion(e,elabel)) / 2\n",
    "  print(loss)\n",
    "  \n",
    "  break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8iCJVtzUVBO"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tNzN6c-xZ_A"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YduImGhxb6q"
   },
   "outputs": [],
   "source": [
    "def test(model,ds,args,tp):\n",
    "    if tp == 'test':\n",
    "        dataset = GetDataset(ds.test,args.model_type,args.device,args.language)\n",
    "        print(f'Testing...{len(dataset)}')\n",
    "    elif tp == 'dev':   \n",
    "        dataset = GetDataset(ds.dev,args.model_type,args.device,args.language)\n",
    "        print(f'Dev...{len(dataset)}')\n",
    "    loader = DataLoader(dataset,batch_size=args.batch_size,shuffle=True)\n",
    "    model.eval()\n",
    "    loss,i = 0,0\n",
    "    print(loss,i)\n",
    "    criterion = nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            i = i+1\n",
    "            inp_ids,tok_id,att_m ,slabel,elabel = batch['input_ids'],batch['token_type_ids'],batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\n",
    "            s,e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            loss += batch_loss\n",
    "            \n",
    "        print(f'Result: LOSS: {loss} AVG: {loss/i} ')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYP5p7oaxXQF"
   },
   "source": [
    "# Train\n",
    "+ train(ds,w_d,lr_rate,device,model_type,epoches):\n",
    "+ data(還沒封裝) , weight_d , learningrate , device , model_type , epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGbz1SUhxcb2"
   },
   "outputs": [],
   "source": [
    "def train(ds,args):\n",
    "    dataset = GetDataset(ds.train,args.model_type,args.device,args.language)\n",
    "    trainLoader = DataLoader(dataset,batch_size=args.batch_size,shuffle=True)\n",
    "    model = bertDRCD(args.model_type).to(args.device)\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = AdamW(parameters, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    minloss = 100000\n",
    "    for ei in range(args.epoch):\n",
    "        model.train()\n",
    "        epoch_loss,i,check_loss = 0,0,0\n",
    "        for batch in trainLoader:\n",
    "            i+=1\n",
    "            inp_ids,tok_id,att_m ,slabel,elabel = batch['input_ids'],batch['token_type_ids'],batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\n",
    "            s,e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            epoch_loss += batch_loss\n",
    "            check_loss += batch_loss\n",
    "            #print(batch_loss)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 1000==0:\n",
    "                print(f'1000 batch LOSS {check_loss}')\n",
    "                check_loss = 0\n",
    "        print(f'Epoches: {ei} Loss {epoch_loss} ')\n",
    "        dev_loss = test(model,ds,args,'dev') \n",
    "        if dev_loss < minloss:\n",
    "            minloss = dev_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llu-ld14gYdA"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8P9_YXsgaCT",
    "outputId": "b0d26f7b-3f4a-4300-f0a8-0feb6d9e9874"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, device=device(type='cuda', index=0), epoch=5, language='tw', learning_rate=1e-05, model_type='hfl/chinese-roberta-wwm-ext', weight_decay=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser([])\n",
    "parser.add_argument('--batch-size', default=4 , type=int)\n",
    "parser.add_argument('--epoch', default=5, type=int)\n",
    "parser.add_argument('--learning-rate', default=1e-5, type=float)    \n",
    "parser.add_argument('--weight-decay', default=0.001, type=float)\n",
    "parser.add_argument('--model-type', default='hfl/chinese-roberta-wwm-ext' , type=str)  #model_type = 'hfl/chinese-bert-wwm'  'hfl/chinese-roberta-wwm-ext'  'hfl/chinese-roberta-wwm-ext-large'\n",
    "parser.add_argument('--device', default=torch.device('cuda:0'), type=int)\n",
    "parser.add_argument('--language', default='tw', type=str)\n",
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac4TkXWchw4L"
   },
   "outputs": [],
   "source": [
    "ds = DRCDdataset(train_path='./dataset/DRCD_train.json',test_path='./dataset/DRCD_test.json',dev_path='./dataset/DRCD_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "eHUEmYLLq1C7",
    "outputId": "50541229-7afa-4efe-ea24-a2a3a7330e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，高峰時期每小時單向客流高達26900人次，僅次於波哥大的快速交通系統，平均每10秒鐘就有一輛巴士，每輛巴士單向行駛350小時。包括橋樑在內的站台是世界最長的州快速公交運輸系統站台，長達260米。目前廣州市區的計程車和公共汽車主要使用液化石油氣作燃料，部分公共汽車更使用油電、氣電混合動力技術。2012年底開始投放液化天然氣燃料的公共汽車，2014年6月開始投放液化天然氣插電式混合動力公共汽車，以取代液化石油氣公共汽車。2007年1月16日，廣州市政府全面禁止在市區內駕駛摩托車。違反禁令的機動車將會予以沒收。廣州市交通局聲稱禁令的施行，使得交通擁擠問題和車禍大幅減少。廣州白雲國際機場位於白雲區與花都區交界，2004年8月5日正式投入運營，屬中國交通情況第二繁忙的機場。該機場取代了原先位於市中心的無法滿足日益增長航空需求的舊機場。目前機場有三條飛機跑道，成為國內第三個擁有三跑道的民航機場。比鄰近的香港國際機場第三跑道預計的2023年落成早8年。',\n",
       "  '廣州的快速公交運輸系統每多久就會有一輛巴士？',\n",
       "  '10秒鐘']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "bEyDq_PC1i82",
    "outputId": "6e6dafc9-e7b0-408f-8b80-337644122cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "1000 batch LOSS 8.626931190490723\n",
      "1000 batch LOSS 4.643729209899902\n",
      "1000 batch LOSS 4.884631633758545\n",
      "1000 batch LOSS 3.8254661560058594\n",
      "1000 batch LOSS 4.048442840576172\n",
      "1000 batch LOSS 4.460489749908447\n",
      "Epoches: 0 Loss 33.80564880371094 \n",
      "Dev...3524\n",
      "0 0\n",
      "Result: LOSS: 3.2324342727661133 AVG: 0.0036690514534711838 \n",
      "1000 batch LOSS 3.6819632053375244\n",
      "1000 batch LOSS 2.970808744430542\n",
      "1000 batch LOSS 3.835580825805664\n",
      "1000 batch LOSS 3.925830364227295\n",
      "1000 batch LOSS 3.231854200363159\n",
      "1000 batch LOSS 3.097957134246826\n",
      "Epoches: 1 Loss 23.001644134521484 \n",
      "Dev...3524\n",
      "0 0\n",
      "Result: LOSS: 3.1757328510284424 AVG: 0.003604691242799163 \n",
      "1000 batch LOSS 3.025343418121338\n",
      "1000 batch LOSS 2.7990355491638184\n",
      "1000 batch LOSS 3.188946485519409\n",
      "1000 batch LOSS 3.041139841079712\n",
      "1000 batch LOSS 2.3215901851654053\n",
      "1000 batch LOSS 2.741631269454956\n",
      "Epoches: 2 Loss 19.335426330566406 \n",
      "Dev...3524\n",
      "0 0\n",
      "Result: LOSS: 3.1719062328338623 AVG: 0.0036003477871418 \n",
      "1000 batch LOSS 2.327446460723877\n",
      "1000 batch LOSS 1.9176737070083618\n",
      "1000 batch LOSS 2.5172817707061768\n",
      "1000 batch LOSS 3.4986636638641357\n",
      "1000 batch LOSS 2.5750691890716553\n",
      "1000 batch LOSS 2.7557225227355957\n",
      "Epoches: 3 Loss 17.13115692138672 \n",
      "Dev...3524\n",
      "0 0\n",
      "Result: LOSS: 3.522876024246216 AVG: 0.003998724278062582 \n",
      "1000 batch LOSS 2.349576473236084\n",
      "1000 batch LOSS 2.021045207977295\n",
      "1000 batch LOSS 2.3141844272613525\n",
      "1000 batch LOSS 2.3071823120117188\n",
      "1000 batch LOSS 2.3295021057128906\n",
      "1000 batch LOSS 2.7468621730804443\n",
      "Epoches: 4 Loss 15.87288761138916 \n",
      "Dev...3524\n",
      "0 0\n",
      "Result: LOSS: 3.6021335124969482 AVG: 0.004088687710464001 \n",
      "Train end, model name is bertDRCD_0812_0034.pt\n"
     ]
    }
   ],
   "source": [
    "mode = 'train'\n",
    "\n",
    "if mode == 'train': \n",
    "    print('Train')\n",
    "    best_model = train(ds,args)\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')    \n",
    "    modelname = 'bertDRCD'+'_'+(datetime.now()+timedelta(hours=8)).strftime(\"%m%d_%H%M\")+'.pt' \n",
    "    torch.save(best_model, f'saved_models/{modelname}')\n",
    "    print(f'Train end, model name is {modelname}')\n",
    "\n",
    "elif mode == 'test' or mode == 'dev':\n",
    "    modelname = 'bertDRCD_0808_1213.pt'\n",
    "    test_model = bertDRCD(args.model_type).to(args.device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{modelname}'))\n",
    "    test(test_model,ds,args,mode)\n",
    "\n",
    "#22.53021812438965\n",
    "#22.579822540283203\n",
    "# Result: LOSS: 3.2912609577178955 AVG: 0.003765744622796774 \n",
    "# Result: LOSS: 3.526034116744995 AVG: 0.004002308938652277 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7n5HS36ex16"
   },
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVfxojHYfKJT"
   },
   "outputs": [],
   "source": [
    "class DRCD():\n",
    "    def __init__(self,model_path,model_type,language): \n",
    "        # device\n",
    "        # language define the language model wanna eat\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "        # model & tokenizer\n",
    "        # model_type = 'hfl/chinese-roberta-wwm-ext'\n",
    "        config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "        self.model = bertDRCD(model_type).to(self.device)\n",
    "        self.model.load_state_dict(torch.load(model_path)) \n",
    "        self.language = language\n",
    "        # 繁簡轉換\n",
    "        self.c2tw = OpenCC('s2t') # china to tw\n",
    "        self.tw2c = OpenCC('t2s') # tw to china\n",
    "\n",
    "    def process(self,content,question):\n",
    "        \n",
    "        content,question = self.clean_str(content,question)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            token_tensor = self.tokenizer.encode_plus(str(question),str(content),max_length=512,truncation=True,pad_to_max_length=True)\n",
    "            token = torch.tensor(token_tensor['input_ids']).unsqueeze(0).to(self.device)\n",
    "            segment = torch.tensor( token_tensor['token_type_ids']).unsqueeze(0).to(self.device)\n",
    "            mask = torch.tensor( token_tensor['attention_mask'] ).unsqueeze(0).to(self.device)\n",
    "            answer_start,answer_end = self.model(input_ids=token,attention_mask=mask,token_type_ids=segment) \n",
    "      \n",
    "            # get ans\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(token.squeeze())\n",
    "            answer_start = answer_start.argmax(1)\n",
    "            answer_end = answer_end.argmax(1)\n",
    "            #print(answer_start,answer_end)\n",
    "            if answer_start > answer_end :\n",
    "                return '抱歉 這題有點難耶'\n",
    "            \n",
    "            #print(answer_start,answer_end)\n",
    "            answer = ''.join(tokens[answer_start:answer_end+1])\n",
    "            \n",
    "            if self.language == 'tw':\n",
    "                answer = self.c2tw.convert(answer)\n",
    "            \n",
    "            \n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def clean_str(self,content,question):\n",
    "        content = content.replace(' ','')\n",
    "        question = question.replace(' ','')\n",
    "        if self.language == 'china':\n",
    "            content = self.tw2c.convert(content)\n",
    "            question = self.tw2c.convert(question)\n",
    "\n",
    "        return content,question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76m8dUy1ew9t",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelname = 'bertDRCD_0810_0518.pt'\n",
    "#myfriend = DRCD(f'saved_models/{modelname}','hfl/chinese-roberta-wwm-ext','tw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSFpusMof5hi"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myfriend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-47b08b083bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2014年世界盃外圍賽，韓國在首輪分組賽以首名出線次輪分組賽，與伊朗、卡達、烏茲別克以及黎巴嫩爭逐兩個直接出線決賽周資格，最後韓國僅以較佳的得失球差壓倒烏茲別克，以小組次名取得2014年世界盃決賽周參賽資格，也是韓國連續八次晉身世界盃決賽周。可惜南韓在決賽周表現不濟，三戰一和兩負小組末席出局。2018年世界盃外圍賽，韓國再次在首輪分組賽以首名出線次輪分組賽，再與伊朗、卡達、烏茲別克同組，同組還有中國及敘利亞。最後韓國以兩分壓倒敘利亞及烏茲別克，再以小組次名取得2018年世界盃決賽周參賽資格，也是韓國連續九次晉身世界盃決賽周。韓國的世界盃成績雖然是亞洲最佳，但在亞洲盃足球賽成績就遠不如世界盃。韓國除了在首兩屆亞洲杯奪冠外，但之後一直與亞洲盃錦標無緣，自1992年至2011年更連續六屆未能打入過亞洲盃決賽。2015年亞洲盃足球賽，韓國以五連勝一球不失的姿態，廿七年來首次打入亞洲盃決賽，對手是東道主澳洲。雖然韓國在分組初賽曾以1-0擊敗澳洲，但這場決賽韓國卻先失一球，最後在下半場補時階段扳平，令比賽進入加時階段，可惜澳洲最後在加時階段攻入致勝一球，最後韓國以1-2敗陣，只得亞軍。'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"哪一個國家負責舉辦2015年亞洲盃足球賽?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfriend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myfriend' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#content = '福茂唱片音樂股份有限公司是一家臺灣唱片公司，成立於1961年，由福茂工程創辦人張人鳳及次子張耕宇先生創立。曾為環球音樂旗下子公司之一。至2002年，正式退出環球音樂旗下，成為獨立唱片公司。成立初期，福茂為英國迪卡唱片在台灣的獨家代理公司，1986年成立國語部，開始發展國語唱片市場，庾澄慶為第一個與福茂唱片簽約的台灣歌手。其後福茂一手捧紅歌手包括庾澄慶、邰正宵、辛曉琪、林隆璇和范曉萱等人。1989年福茂唱片引進CD技術，發行的首張CD專輯是庾澄慶的《讓我一次愛個夠》，銷量40萬張，並入選台灣百佳唱片第48位。1992年，迪卡唱片母公司寶麗金唱片向福茂買入60%股權，福茂也同時加入寶麗金唱片旗下；福茂英文名稱因此改為「Decca Records Taiwan Ltd.」並使用迪卡唱片商標。首張以迪卡唱片商標發行的唱片是庾澄慶首張英文專輯《哈林音樂電台》。在此時期，福茂一手捧紅大陸歌手那英和香港歌手周慧敏、蘇永康、王菲等在台灣的國語市場。1999年，寶麗金唱片集團被現時的環球唱片收購，福茂也曾為環球旗下子公司之一。'\n",
    "content = '2014年世界盃外圍賽，韓國在首輪分組賽以首名出線次輪分組賽，與伊朗、卡達、烏茲別克以及黎巴嫩爭逐兩個直接出線決賽周資格，最後韓國僅以較佳的得失球差壓倒烏茲別克，以小組次名取得2014年世界盃決賽周參賽資格，也是韓國連續八次晉身世界盃決賽周。可惜南韓在決賽周表現不濟，三戰一和兩負小組末席出局。2018年世界盃外圍賽，韓國再次在首輪分組賽以首名出線次輪分組賽，再與伊朗、卡達、烏茲別克同組，同組還有中國及敘利亞。最後韓國以兩分壓倒敘利亞及烏茲別克，再以小組次名取得2018年世界盃決賽周參賽資格，也是韓國連續九次晉身世界盃決賽周。韓國的世界盃成績雖然是亞洲最佳，但在亞洲盃足球賽成績就遠不如世界盃。韓國除了在首兩屆亞洲杯奪冠外，但之後一直與亞洲盃錦標無緣，自1992年至2011年更連續六屆未能打入過亞洲盃決賽。2015年亞洲盃足球賽，韓國以五連勝一球不失的姿態，廿七年來首次打入亞洲盃決賽，對手是東道主澳洲。雖然韓國在分組初賽曾以1-0擊敗澳洲，但這場決賽韓國卻先失一球，最後在下半場補時階段扳平，令比賽進入加時階段，可惜澳洲最後在加時階段攻入致勝一球，最後韓國以1-2敗陣，只得亞軍。'\n",
    "question = \"哪一個國家負責舉辦2015年亞洲盃足球賽?\"\n",
    "ans = myfriend.process(content,question)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor q in question:\\n    print(q + ':  '+ myfriend.process(content,q))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \\\n",
    "'美國國家情報總監辦公室7日發布新聞稿，分析外國影響美國總統選舉的最新情勢。美方評估，北京認為美國總統川普「無法預測」，希望川普不要贏得連任。川普說，若拜登當總統，則「中國將擁有我們這個國家。」\\\n",
    "川普7日晚間在紐澤西的鄉村俱樂部舉行記者會，被問到此事說，中國大陸、俄羅斯和伊朗都不想看到他贏得選舉，「若拜登當總統，則中國將擁有我們這個國家。」他也暗示，這三個國家可能透過郵寄投票，在美國大選中作弊。\\\n",
    "川普稱自己已聽取這分簡報，但似乎沒搞清楚內容，記者詢問「俄羅斯正在傷害拜登、而中國想看到你輸，你相信這分情報嗎？」\\\n",
    "川普說，可能是真的、可能是假的，實際上他做了很多事，包括醫療物資的儲備系統和軍隊，其中促使北約(NATO)各國提高軍事預算，用來抵抗俄羅斯，「沒人像我對俄羅斯這麼強硬，俄羅斯最不想看到我當選。」\\\n",
    "川普說，中國大陸做夢都想看到拜登打敗他成為總統，「若拜登是總統，則中國會擁有我們這個國家。」\\\n",
    "當記者試圖糾正川普，他接著說，「你沒把報告看清楚吧，報告裡還有個伊朗，伊朗也不想看到我當總統，但我要說，若我贏得連任，我會很快與伊朗、與北韓達成協議；若不是我2016年當選總統，可能美朝之間早已開戰。」\\\n",
    "川普說，若拜登主政下的美國，與中國大陸達成任何協議，則中國大陸會擁有美國；他則可以從中國大陸手中，拿到數百億美元，且美國現在一片欣欣向榮，各種指數表現良好。\\\n",
    "川普說，中國大陸、俄羅斯和伊朗都不想看到他連任，但是最大威脅不是這三個國家，是郵寄投票，包括這些國家甚至北韓等國，都可以在這裡作弊，他會仔細留意這個大問題。'\n",
    "\n",
    "print(len(content))\n",
    "\n",
    "question = ['蒂埃里·亨利是誰','蒂埃里·亨利為法國隊出場幾次','亨利曾在國際比賽中上演過帽子戲法嗎?',\n",
    "            '蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?','亨利在熱身賽中共打進多少球?']\n",
    "\"\"\"\n",
    "for q in question:\n",
    "    print(q + ':  '+ myfriend.process(content,q))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蒂埃里·亨利是誰:  前法國足球運動員\n",
      "蒂埃里·亨利為法國隊出場幾次:  123次\n",
      "亨利曾在國際比賽中上演過帽子戲法嗎?:  從未\n",
      "蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?:  2004年\n",
      "亨利在熱身賽中共打進多少球?:  16球\n"
     ]
    }
   ],
   "source": [
    "content = \\\n",
    "'蒂埃里·亨利是前法國足球運動員。在他職業生涯參加的國際賽事中，他為法國隊出場123次，\\\n",
    "打進51球。他的首個國際比賽進球是在1998年世界盃對陣南非的比賽中。截至2015年10月，他是法國隊的頭號射手\\\n",
    "。2007年10月，他在對陣立陶宛的比賽中打進兩球，打破了米歇爾·普拉蒂尼42球的法國隊進球紀錄。亨利於2010年7月正式退役\\\n",
    "。亨利在2009年10月對奧地利的比賽中打進了個人國家隊第51粒進球，這也是他的最後一粒進球\\\n",
    "。亨利從未在國際比賽中上演過帽子戲法，儘管他曾7次在單場比賽梅開二度。\\\n",
    "他在對陣馬爾他的比賽中進球最多，在2004年歐洲國家盃外圍賽中曾單場上演大四喜。\\\n",
    "亨利一半以上的進球來自於主場比賽，他的51個進球中有31個是在法國本土打進，\\\n",
    "其中有20個在法蘭西體育場。亨利在熱身賽中共打進16球。在2003年國際足總洲際國家盃上\\\n",
    "，亨利打進四球並榮膺最佳射手，他也因此被評為「賽事最傑出球員」。\\\n",
    "亨利在歐洲國家盃外圍賽中打入12球，其中在2004年歐洲杯外圍賽打進6球，他最終排在射手榜第三位。'\n",
    "\n",
    "question = ['蒂埃里·亨利是誰','蒂埃里·亨利為法國隊出場幾次','亨利曾在國際比賽中上演過帽子戲法嗎?',\n",
    "            '蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?','亨利在熱身賽中共打進多少球?']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ myfriend.process(content,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfriend = DRCD(f'saved_models/{modelname}','hfl/chinese-roberta-wwm-ext','tw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "罷免韓國瑜第二階段有通過嗎:  2020年4月17日，高雄市選舉委員會公告罷免有效聯署書達到37.7萬，罷韓第二階段通過\n",
      "中華民國選舉史上首位被罷免成功的縣市首長是誰:  韓國瑜\n",
      "罷免有效聯署書達到多少?:  37.7萬\n",
      "韓國瑜在哪天正式解職:  6月12日\n",
      "韓國瑜幾歲被轉入放牛班:  國中三年級\n",
      "韓國瑜每天上課一直看誰小腿:  前排女同學\n",
      "韓國瑜的碩士論文名稱?:  《從中共「對臺統戰」策略看兩航談判》\n",
      "韓國瑜退伍前一年考上什麼:  東吳大學英國語文學系\n",
      "韓國瑜為什麼成績一落千丈:  青春期懵懂，每天上課一直看前排女同學的小腿\n",
      "韓國瑜擔任誰的助理:  馮定國\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "content = '2020年4月17日，高雄市選舉委員會公告罷免有效聯署書達到37.7萬，罷韓第二階段通過\\\n",
    "，韓國瑜成為全國第一位被罷免投票兩次者、也成為首個市長罷免案進入投票階段的市長。2020年6月6日\\\n",
    "，罷免投票通過，6月12日中央選舉委員會公告結果後正式解職\\\n",
    "，韓國瑜成為中華民國選舉史上首位被罷免成功的縣市首長。\\\n",
    "韓國瑜曾自述，他在年少求學階段考試都考第一名，但國中二年級開始因青春期懵懂，\\\n",
    "每天上課一直看前排女同學的小腿，成績一落千丈，國中三年級被轉入放牛班，逃學翹課\\\n",
    "、打撞球、打架也樣樣俱全，最後在父母決定下，18歲時入中華民國陸軍軍官學校專修學生班40期\\\n",
    "，軍銜升至上尉，自稱在軍中受一位國立臺灣大學醫學系畢業的預官轉魔術方塊的啟發，感到自己的不足\\\n",
    "，決定重拾課本。退伍前一年考上東吳大學英國語文學系，\\\n",
    "畢業後又考取國立政治大學東亞研究所和淡江大學國際事務與戰略研究所。\\\n",
    "由於政大免學費還發獎學金故選擇政大東亞所就讀。就讀期間擔任臺北市議員馮定國的助理，\\\n",
    "畢業後獲法學碩士學位。碩士論文名稱為《從中共「對臺統戰」策略看兩航談判》，指導教授為蘇起。'\n",
    "\n",
    "question = ['罷免韓國瑜第二階段有通過嗎','中華民國選舉史上首位被罷免成功的縣市首長是誰'\n",
    "            ,'罷免有效聯署書達到多少?','韓國瑜在哪天正式解職','韓國瑜幾歲被轉入放牛班'\n",
    "            ,'韓國瑜每天上課一直看誰小腿','韓國瑜的碩士論文名稱?',\n",
    "            '韓國瑜退伍前一年考上什麼','韓國瑜為什麼成績一落千丈','韓國瑜擔任誰的助理']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ myfriend.process(content,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeXT公司是誰創造的:  賈伯斯\n",
      "NeXT公司是在哪年成立:  1985年\n",
      "誰決議買下NeXT公司:  董事會\n",
      "誰成立了皮克斯:  賈伯斯\n",
      "誰是《玩具總動員》的執行製片人:  賈伯斯\n",
      "皮克斯動畫在哪年被華特迪士尼公司收購:  2006年\n"
     ]
    }
   ],
   "source": [
    "content = '賈伯斯在1970年代末與蘋果公司另一始創人史蒂夫·沃茲尼克及首任投資者邁克·馬庫拉協同其他人設計、\\\n",
    "開發及銷售Apple II系列。在1980年代初，賈伯斯是最早看到全錄帕洛奧圖中心（Xerox PARC）的滑鼠驅動圖形用戶介面的商業潛力，\\\n",
    "並將其應用於Apple Lisa及一年後的麥金塔電腦。1985年，在董事會的鬥爭失勢後，賈伯斯離開蘋果公司及成立了NeXT公司(一間電腦\\\n",
    "平台開發公司，專門從事高等教育及商業市場)在1986年，他收購了盧卡斯影業的電腦繪圖部門，成立了皮克斯（Pixar）。\\\n",
    "他被譽為《玩具總動員》（1995年）的執行製片人。他一直擔任皮克斯動畫的執行長並持有50.1%的股份，\\\n",
    "直到公司在2006年被華特迪士尼公司收購，此項收購使賈伯斯成為迪士尼公司的最大個人股東（有7.4%的股份）及董事會成員。\\\n",
    "在1996年，蘋果公司董事會決議買下NeXT公司，把賈伯斯帶回他參與創立，卻正在垂死邊緣的蘋果公司擔任臨時CEO。\\\n",
    "他在2000年起成為正式CEO，帶領蘋果輝煌的iPod、iPhone、iPad時代的到來。從2003年10月起，賈伯斯與胰腺神經內分泌腫瘤奮戰了8年，\\\n",
    "最終於2011年8月辭任執行長一職，在他第3次病假期間，賈伯斯當選為蘋果公司的董事長。'\n",
    "\n",
    "\n",
    "question = ['NeXT公司是誰創造的','NeXT公司是在哪年成立','誰決議買下NeXT公司','誰成立了皮克斯'\n",
    "            ,'誰是《玩具總動員》的執行製片人','皮克斯動畫在哪年被華特迪士尼公司收購']\n",
    "\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ myfriend.process(content,q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "叡揚資訊獲得了甚麼獎項:  抱歉 這題有點難耶\n"
     ]
    }
   ],
   "source": [
    "content = f'叡揚資訊近二十幾年發展商業智慧及資料倉儲系統的建置經驗中，\\\n",
    "提供了以數據分析及 AI 輔助的智慧醫療與智慧零售的解決方案，\\\n",
    "更因此獲得了2019 APICTA Awards 大數據應用銀牌的肯定。\\\n",
    "APICTA 亞太資通訊聯盟大賽，這個舉辦已 18 屆，\\\n",
    "每年超過 200 個各國企業／團隊參賽的競賽，是亞太區最具影響力的資通訊科技競賽，\\\n",
    "更有亞太資通訊科技奧斯卡獎之稱。感謝評審對叡揚大數據應用解決方案肯定，\\\n",
    "對台灣的軟實力更是一劑強心針讓台灣與叡揚在國際的舞台繼續發光發熱。'\n",
    "\n",
    "question = ['APICTA 亞太資通訊聯盟大賽每ㄋㄧㄞˊ']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ myfriend.process(content,q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 1, 2, 0, 1, 2]\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2222222222222222, 0.3333333333333333, 0.26666666666666666, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
    "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
    "precision_recall_fscore_support(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNVM3uYt3pO9lYSGqAyojSw",
   "collapsed_sections": [
    "1Rru4MXtiSQ0"
   ],
   "include_colab_link": true,
   "name": "trainDRCD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
